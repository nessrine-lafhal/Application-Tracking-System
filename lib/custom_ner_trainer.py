import spacy
from spacy.tokens import DocBin
from spacy.training.example import Example
from spacy.util import minibatch, compounding
import random
import warnings
import json
import os
from typing import List, Tuple, Dict, Any

warnings.filterwarnings("ignore")

class CustomNERTrainer:
    def __init__(self, model_name="ner_recruitment_model"):
        self.model_name = model_name
        self.model_path = f"models/{model_name}"
        
        # Donn√©es d'entra√Ænement sp√©cifiques au recrutement avec noms arabes
        self.training_data = [
            # Candidats avec noms arabes
            ("ÿ£ÿ≠ŸÖÿØ ÿ®ŸÜ ÿπŸÑŸä est un d√©veloppeur Python avec 5 ans d'exp√©rience chez Google.", {
                "entities": [(0, 12, "PERSON"), (29, 35, "SKILL"), (58, 64, "ORG")]
            }),
            ("ŸÅÿßÿ∑ŸÖÿ© ÿßŸÑŸÖŸÜÿµŸàÿ±Ÿä a des comp√©tences en React et Angular, elle a travaill√© chez Microsoft.", {
                "entities": [(0, 14, "PERSON"), (38, 43, "SKILL"), (47, 54, "SKILL"), (78, 87, "ORG")]
            }),
            ("ŸÖÿ≠ŸÖÿØ ÿßŸÑÿ∑ÿ±ÿßÿ®ŸÑÿ≥Ÿä ma√Ætrise Java, Spring Boot et a une exp√©rience de 3 ans chez IBM.", {
                "entities": [(0, 14, "PERSON"), (24, 28, "SKILL"), (30, 41, "SKILL"), (74, 77, "ORG")]
            }),
            ("ÿ≤ŸäŸÜÿ® ÿßŸÑÿ≠ŸÖÿßŸÖŸä est sp√©cialis√©e en Data Science et Machine Learning chez Amazon.", {
                "entities": [(0, 12, "PERSON"), (32, 44, "SKILL"), (48, 64, "SKILL"), (70, 76, "ORG")]
            }),
            ("ÿπŸÖÿ± ÿ®ŸÜ ŸäŸàÿ≥ŸÅ d√©veloppe des applications mobiles avec Flutter et React Native.", {
                "entities": [(0, 11, "PERSON"), (55, 62, "SKILL"), (66, 78, "SKILL")]
            }),
            
            # Comp√©tences techniques
            ("Exp√©rience avec Docker, Kubernetes et AWS pour le d√©ploiement cloud.", {
                "entities": [(16, 22, "SKILL"), (24, 34, "SKILL"), (38, 41, "SKILL")]
            }),
            ("Ma√Ætrise de PostgreSQL, MongoDB et Redis pour la gestion de donn√©es.", {
                "entities": [(12, 22, "SKILL"), (24, 31, "SKILL"), (35, 40, "SKILL")]
            }),
            ("Comp√©tences en TensorFlow, PyTorch et scikit-learn pour l'IA.", {
                "entities": [(15, 25, "SKILL"), (27, 34, "SKILL"), (38, 50, "SKILL")]
            }),
            
            # Entreprises et organisations
            ("Il a travaill√© chez TechCorp, StartupTN et Universit√© de Tunis.", {
                "entities": [(20, 28, "ORG"), (30, 39, "ORG"), (43, 63, "ORG")]
            }),
            ("Formation √† l'ENSI, ESPRIT et √âcole Polytechnique de Tunisie.", {
                "entities": [(15, 19, "ORG"), (21, 27, "ORG"), (31, 61, "ORG")]
            }),
            
            # Lieux
            ("Bas√© √† Tunis, disponible pour missions √† Sfax et Sousse.", {
                "entities": [(7, 12, "LOC"), (42, 46, "LOC"), (50, 56, "LOC")]
            }),
            ("Exp√©rience internationale: Paris, Londres et Dubai.", {
                "entities": [(31, 36, "LOC"), (38, 45, "LOC"), (49, 54, "LOC")]
            }),
            
            # Certifications et dipl√¥mes
            ("Certifi√© AWS Solutions Architect et Google Cloud Professional.", {
                "entities": [(9, 33, "CERTIFICATION"), (37, 62, "CERTIFICATION")]
            }),
            ("Dipl√¥me d'Ing√©nieur en Informatique et Master en Data Science.", {
                "entities": [(8, 34, "EDUCATION"), (38, 62, "EDUCATION")]
            }),
            
            # Projets et r√©alisations
            ("D√©veloppement d'une plateforme e-commerce avec React et Node.js.", {
                "entities": [(51, 56, "SKILL"), (60, 67, "SKILL")]
            }),
            ("Cr√©ation d'un syst√®me de recommandation bas√© sur Machine Learning.", {
                "entities": [(49, 66, "SKILL")]
            }),
            
            # Soft skills
            ("Excellentes comp√©tences en communication, leadership et travail d'√©quipe.", {
                "entities": [(27, 40, "SOFT_SKILL"), (42, 52, "SOFT_SKILL"), (56, 72, "SOFT_SKILL")]
            }),
            ("Capacit√© d'adaptation, r√©solution de probl√®mes et pens√©e analytique.", {
                "entities": [(0, 21, "SOFT_SKILL"), (23, 46, "SOFT_SKILL"), (50, 67, "SOFT_SKILL")]
            }),
            
            # Langues
            ("Parle couramment Arabe, Fran√ßais et Anglais.", {
                "entities": [(17, 22, "LANGUAGE"), (24, 32, "LANGUAGE"), (36, 43, "LANGUAGE")]
            }),
            ("Niveau natif en Arabe, professionnel en Anglais et interm√©diaire en Allemand.", {
                "entities": [(16, 21, "LANGUAGE"), (40, 47, "LANGUAGE"), (68, 76, "LANGUAGE")]
            }),
        ]

    def create_ner_model(self):
        """Cr√©e et entra√Æne un mod√®le NER personnalis√©"""
        print("üöÄ Cr√©ation du mod√®le NER personnalis√©...")
        
        # Cr√©er un mod√®le vide
        nlp = spacy.blank("fr")  # Utiliser fran√ßais comme base
        
        # Ajouter le composant NER
        ner = nlp.add_pipe("ner", last=True)
        
        # Ajouter toutes les √©tiquettes
        labels = ["PERSON", "SKILL", "ORG", "LOC", "CERTIFICATION", "EDUCATION", 
                 "SOFT_SKILL", "LANGUAGE", "PRODUCT", "EXPERIENCE"]
        
        for label in labels:
            ner.add_label(label)
        
        # Ajouter les √©tiquettes trouv√©es dans les donn√©es d'entra√Ænement
        for _, annotations in self.training_data:
            for ent in annotations.get("entities", []):
                ner.add_label(ent[2])
        
        return nlp

    def train_model(self, iterations=20):
        """Entra√Æne le mod√®le NER"""
        print(f"üéØ Entra√Ænement du mod√®le sur {len(self.training_data)} exemples...")
        
        nlp = self.create_ner_model()
        
        # Initialiser l'optimiseur
        nlp.initialize()
        
        # Entra√Ænement
        for i in range(iterations):
            random.shuffle(self.training_data)
            losses = {}
            
            # Cr√©er des batches
            batches = minibatch(self.training_data, size=compounding(2.0, 16.0, 1.5))
            
            for batch in batches:
                examples = []
                for text, annotations in batch:
                    doc = nlp.make_doc(text)
                    examples.append(Example.from_dict(doc, annotations))
                
                nlp.update(examples, drop=0.2, losses=losses)
            
            print(f"It√©ration {i+1}/{iterations} - Pertes: {losses}")
        
        # Cr√©er le dossier models s'il n'existe pas
        os.makedirs("models", exist_ok=True)
        
        # Sauvegarder le mod√®le
        nlp.to_disk(self.model_path)
        print(f"‚úÖ Mod√®le sauvegard√© dans {self.model_path}")
        
        return nlp

    def load_model(self):
        """Charge le mod√®le entra√Æn√©"""
        try:
            nlp = spacy.load(self.model_path)
            print(f"‚úÖ Mod√®le charg√© depuis {self.model_path}")
            return nlp
        except OSError:
            print(f"‚ùå Mod√®le non trouv√© dans {self.model_path}")
            print("üîÑ Entra√Ænement d'un nouveau mod√®le...")
            return self.train_model()

    def extract_entities(self, text: str) -> Dict[str, List[str]]:
        """Extrait les entit√©s d'un texte avec le mod√®le personnalis√©"""
        nlp = self.load_model()
        doc = nlp(text)
        
        entities = {
            "PERSON": [],
            "SKILL": [],
            "ORG": [],
            "LOC": [],
            "CERTIFICATION": [],
            "EDUCATION": [],
            "SOFT_SKILL": [],
            "LANGUAGE": [],
            "PRODUCT": [],
            "EXPERIENCE": []
        }
        
        for ent in doc.ents:
            if ent.label_ in entities:
                entities[ent.label_].append(ent.text.strip())
        
        # Nettoyer les doublons
        for key in entities:
            entities[key] = list(set(entities[key]))
        
        return entities

    def test_model(self, test_texts: List[str] = None):
        """Teste le mod√®le sur des exemples"""
        if test_texts is None:
            test_texts = [
                "ÿ£ÿ≠ŸÖÿØ ÿ®ŸÜ ÿπŸÑŸä est un d√©veloppeur Python exp√©riment√© chez Google √† Tunis.",
                "ŸÅÿßÿ∑ŸÖÿ© ÿßŸÑŸÖŸÜÿµŸàÿ±Ÿä ma√Ætrise React, Angular et a un Master en Informatique.",
                "Comp√©tences: Docker, Kubernetes, AWS, leadership et communication.",
                "Certifi√© AWS Solutions Architect, parle Arabe, Fran√ßais et Anglais."
            ]
        
        nlp = self.load_model()
        
        print("\nüß™ Test du mod√®le NER personnalis√©:")
        print("=" * 50)
        
        for text in test_texts:
            print(f"\nTexte: {text}")
            doc = nlp(text)
            
            if doc.ents:
                print("Entit√©s d√©tect√©es:")
                for ent in doc.ents:
                    print(f"  - {ent.text} ({ent.label_})")
            else:
                print("  Aucune entit√© d√©tect√©e")

    def add_training_data(self, new_data: List[Tuple[str, Dict]]):
        """Ajoute de nouvelles donn√©es d'entra√Ænement"""
        self.training_data.extend(new_data)
        print(f"‚úÖ {len(new_data)} nouveaux exemples ajout√©s")

    def retrain_model(self, new_data: List[Tuple[str, Dict]] = None):
        """R√©entra√Æne le mod√®le avec de nouvelles donn√©es"""
        if new_data:
            self.add_training_data(new_data)
        
        print("üîÑ R√©entra√Ænement du mod√®le...")
        return self.train_model()

# Fonction utilitaire pour l'int√©gration avec l'ATS
def get_recruitment_ner_model():
    """Retourne une instance du mod√®le NER pour le recrutement"""
    trainer = CustomNERTrainer()
    return trainer.load_model()

def extract_recruitment_entities(text: str) -> Dict[str, List[str]]:
    """Extrait les entit√©s sp√©cifiques au recrutement d'un texte"""
    trainer = CustomNERTrainer()
    return trainer.extract_entities(text)

# Ex√©cution principale pour l'entra√Ænement
if __name__ == "__main__":
    trainer = CustomNERTrainer()
    
    # Entra√Æner le mod√®le
    trainer.train_model()
    
    # Tester le mod√®le
    trainer.test_model()
